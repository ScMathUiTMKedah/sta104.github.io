# Simple Linear Regression

In this chapter, we explore the concept of simple linear regression, a statistical method used to model the relationship between a single independent variable (predictor) and a dependent variable (response). We cover the theory behind simple linear regression, how to fit a regression line to data, assess the goodness of fit, and make predictions using the regression model.

## 1. Introduction to Simple Linear Regression

Simple linear regression seeks to find the best-fitting straight line through a set of data points, assuming a linear relationship between the independent variable $x$ and the dependent variable $y$. The regression line is represented by the equation:

$y = \beta_0 + \beta_1x + \varepsilon$

Where:
- $y$ is the dependent variable,
- $x$ is the independent variable,
- $\beta_0$ is the intercept,
- $\beta_1$ is the slope,
- $\varepsilon$ is the error term.

## 2. Fitting the Regression Line

The regression line is fitted using the method of least squares. The slope $\beta_1$ and intercept $\beta_0$ are calculated using the formulas:

$\beta_1 = \frac{{\sum(x_i - \bar{x})(y_i - \bar{y})}}{{\sum(x_i - \bar{x})^2}}$

$\beta_0 = \bar{y} - \beta_1\bar{x}$

Where:
- $(x_i, y_i)$ are the individual data points,
- $\bar{x}$ and $\bar{y}$ are the means of $x$ and $y$, respectively.

## 3. Assessing Goodness of Fit

The coefficient of determination $R^2$ measures the proportion of variance in the dependent variable explained by the independent variable. It ranges from 0 to 1, with higher values indicating a better fit.

$R^2 = \frac{{\text{SSR}}}{{\text{SST}}}$

Where:
- SSR (Sum of Squares Regression) measures explained variation,
- SST (Total Sum of Squares) measures total variation.

## 4. Making Predictions

The regression line can be used to make predictions for new values of $x$. Simply plug the new value into the regression equation and calculate the corresponding predicted value of $y$.

## Example

A manager desires to know whether the typing speed of a secretary (in words per minute) is related to the time (in hours) that it takes the secretary to learn to use a new word processing
program. The data are recorded as follows:

*Insert Data Table Here*

Suppose we have the following data:

```{r}
# Sample data
x <- c(48,74,52,79,83,56,85,
       63,88,74,90,92)
y <- c(7,4,8,3.5,2,6,2.3,
       5,2.1,4.5,1.9,1.5)
```

### Fitting the Regression Line

```{r}
# Calculate means
x_bar <- mean(x)
y_bar <- mean(y)

# Calculate slope
beta_1 <- sum((x - x_bar) * (y - y_bar)) / sum((x - x_bar)^2)

# Calculate intercept
beta_0 <- y_bar - beta_1 * x_bar
```

### Assessing Goodness of Fit

```{r}
# Calculate predicted y values
y_pred <- beta_0 + beta_1 * x

# Calculate SSE
SSE <- sum((y - y_pred)^2)

# Calculate SST
SST <- sum((y - y_bar)^2)

# Calculate R^2
R_squared <- 1 - SSE / SST
```

### Making Predictions

```{r}
# Predict y for new value of x
new_x <- 6
predicted_y <- beta_0 + beta_1 * new_x
```

### Result

```{r}
#| message: false
#| warning: false

# Using stargazer to display regression results
library(stargazer)

# Fit linear regression model
lm_model <- lm(y ~ x)

# Print regression results
stargazer(lm_model, type = "text")
```

This concludes our discussion on simple linear regression. By understanding the principles outlined here, you'll be equipped to analyze and interpret the relationship between variables and make predictions using regression models.

::: {.callout}
## Solved Example 1

The following data shows the time taken for special tutorial in hours and exam score (out of 100) for a random sample of 10 students.

Time: 10, 15, 12, 20, 8, 16, 14, 18, 12, 22.
Score: 76, 81, 79, 89, 70, 80, 78, 82, 81, 91

```{r}
# Given data
time <- c(10, 15, 12, 20, 8, 16, 14, 18, 12, 22)
score <- c(76, 81, 79, 89, 70, 80, 78, 82, 81, 91)

# Plot scatter plot
plot(time, score, 
     xlab = "Time (hours)", 
     ylab = "Exam Score", 
     main = "Scatter Plot",
     pch = 16, 
     col = "blue")

```

a) Based on scatter diagram above, briefly describe on the relationship between the two variables. (2 marks)

b) Compute the Pearson Product Moment Correlation Coefficient on the given data. Explain the value obtained. (5 marks)

c) Find the least squares regression equation line for the given data. (4 marks)

d) State the intercept value. Interpret the meaning of the value obtained. (2 marks)

e) What does the slope tell you about the time taken tutorial hours and exam score? (2 marks)

f) Calculate the value of the coefficient of determination. Interpret the meaning.
(2 marks)
g) Predict a person exam score if he has attended special tutorial for 15 hours and 45 minutes. (3 marks)
:::

a) Relationship between the two variables

To describe the relationship between the two variables based on a scatter diagram, we need to plot the given data points (time taken for special tutorial vs. exam score) and observe the pattern.

b) Pearson Product Moment Correlation Coefficient

To compute the Pearson correlation coefficient, denoted by $r$, we use the formula:

$$
r = \frac{{n(\sum xy) - (\sum x)(\sum y)}}{{\sqrt{[n\sum x^2 - (\sum x)^2][n\sum y^2 - (\sum y)^2]}}}
$$

Where:
- $n$ is the number of data points,
- $\sum xy$ is the sum of the products of each pair of $x$ and $y$ values,
- $\sum x$ and $\sum y$ are the sums of the $x$ and $y$ values, respectively,
- $\sum x^2$ and $\sum y^2$ are the sums of the squares of the $x$ and $y$ values, respectively.

Let's calculate $r$ using the provided data.

c) Least Squares Regression Equation
The least squares regression equation for a simple linear regression model is given by:

$$\hat{y} = a + bx$$

Where:
- $\hat{y}$ is the predicted value of the dependent variable,
- $a$ is the intercept of the regression line,
- $b$ is the slope of the regression line,
- $x$ is the independent variable.

We need to calculate the intercept ($a$) and slope ($b$) using the formulas:

$$b = \frac{{n(\sum xy) - (\sum x)(\sum y)}}{{n\sum x^2 - (\sum x)^2}}$$
$$a = \frac{{\sum y - b(\sum x)}}{n}$$

d) Interpreting the intercept value
The intercept ($a$) represents the value of the dependent variable ($y$) when the independent variable ($x$) is zero. Interpreting the intercept depends on the context of the problem.

e) Interpreting the slope value
The slope ($b$) represents the change in the dependent variable ($y$) for a one-unit change in the independent variable ($x$). Interpreting the slope depends on the units of the variables and the context of the problem.

f) Coefficient of Determination
The coefficient of determination ($R^2$) measures the proportion of the variance in the dependent variable that is predictable from the independent variable. It ranges from 0 to 1, where higher values indicate a better fit of the regression line to the data.

$$R^2 = \frac{{SSR}}{{SST}}$$

Where:
- SSR (Sum of Squares Regression) measures explained variation,
- SST (Total Sum of Squares) measures total variation.

**_Note:_** It is much easier to calculate the value by squaring the value of $r$ if available.

g) Predicting exam score
To predict the exam score for a given time taken for special tutorial, we use the regression equation obtained in part (c).

*Let's proceed with the calculations.*

a) Relationship between the two variables

Based on the scatter plot of the data points, we can observe the pattern and direction of the relationship between the time taken for special tutorial and the exam score. If the points tend to form a straight line sloping upwards from left to right, it indicates a positive linear relationship between the variables. Conversely, if the points tend to form a straight line sloping downwards from left to right, it indicates a negative linear relationship. Additionally, if the points are scattered without any apparent pattern, it suggests a weak or no relationship between the variables.

b) Pearson Product Moment Correlation Coefficient
Given data:
Time: 10, 15, 12, 20, 8, 16, 14, 18, 12, 22
Score: 76, 81, 79, 89, 70, 80, 78, 82, 81, 91

Let's calculate the Pearson correlation coefficient ($r$):

First, we need to calculate the sums:
$$\sum x = 10 + 15 + 12 + 20 + 8 + 16 + 14 + 18 + 12 + 22 = 147$$
$$\sum y = 76 + 81 + 79 + 89 + 70 + 80 + 78 + 82 + 81 + 91 = 807$$
$$\sum xy = (10 \times 76) + (15 \times 81) + (12 \times 79) + \dots + (22 \times 91) = 15259$$
$$\sum x^2 = 10^2 + 15^2 + 12^2 + \dots + 22^2 = 2365$$
$$\sum y^2 = 76^2 + 81^2 + 79^2 + \dots + 91^2 = 64209$$

Now, we substitute these values into the formula for $r$:
$$r = \frac{{10(15259) - (147)(807)}}{{\sqrt{(10 \times 2365 - 147^2)(10 \times 64209 - 807^2)}}}$$

After calculating, we get the value of $r$.

c) Least Squares Regression Equation

To find the least squares regression equation, we need to calculate the slope ($b$) and intercept ($a$).

$$b = \frac{{n(\sum xy) - (\sum x)(\sum y)}}{{n\sum x^2 - (\sum x)^2}}$$
$$a = \frac{{\sum y - b(\sum x)}}{n}$$

Using the sums calculated in part (b):
$$\sum x = 147, \sum y = 807, \sum xy = 15259, \sum x^2 = 2365, \sum y^2 = 64209$$
and $n = 10$,

Substitute the values into the formulas:

$$b = \frac{{10(15259) - (147)(807)}}{{10(2365) - (147)^2}}$$
$$b = \frac{{152590 - 118929}}{{23650 - 21609}}$$
$$b = \frac{{33661}}{{2041}}$$
$$b \approx 16.47$$

$$a = \frac{{807 - (16.47)(147)}}{{10}}$$
$$a = \frac{{807 - 2421.09}}{{10}}$$
$$a \approx -161.91$$

So, the least squares regression equation is:
$$\hat{y} = -161.91 + 16.47x$$

d) Interpreting the intercept value

The intercept ($a$) represents the predicted exam score when the time taken for special tutorial is zero. It indicates the initial level of performance on the exam without any time spent on special tutorial.

e) Interpreting the slope value

The slope ($b$) represents the change in the exam score for a one-unit change in the time taken for special tutorial. It indicates the rate of change in the exam score with respect to the time spent on special tutorial.

f) Coefficient of Determination

To calculate $R^2$, we need to first calculate the predicted values of exam scores ($\hat{y}$) using the regression equation.

For each data point:
$$\hat{y}_i = -161.91 + 16.47x_i$$

Then, we calculate the sum of squares regression (SSR) and total sum of squares (SST) to find $R^2$.

$$SSR = \sum (\hat{y}_i - \bar{y})^2$$
$$SST = \sum (y_i - \bar{y})^2$$

Where $\bar{y}$ is the mean of the exam scores.

After calculating SSR and SST, we can find $R^2$ using the formula:

$$R^2 = \frac{{SSR}}{{SST}}$$

g) Predicting exam score

To predict the exam score for a given time taken for special tutorial, let's say $x = 15.75$ (15 hours and 45 minutes), we use the regression equation:

$$\hat{y} = -161.91 + 16.47(15.75)$$

Now, let's perform the calculations:

$$\hat{y} = -161.91 + 16.47 \times 15.75$$
$$\hat{y} = -161.91 + 258.8925$$
$$\hat{y} \approx 96.9825$$

So, the predicted exam score for a time of 15 hours and 45 minutes is approximately $96.9825$.






